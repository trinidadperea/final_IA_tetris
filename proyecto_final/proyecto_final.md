# **Algoritmos de B√∫squeda local para jugar "Tetris"**

![Imagen inicio](images/img_inicio.jpg)

Integrantes:

- Valerio, Perla

- Perea, Trinidad

___

## 1. **Introducci√≥n**

El presente proyecto tiene como finalidad aplicar y poner en pr√°ctica
los conceptos de algoritmos de b√∫squeda local estudiados en la materia,
mediante el desarrollo de un agente capaz de jugar de forma aut√≥noma al
videojuego Tetris. Este juego, creado por Aleks√©i P√°zhitnov en 1984, se
caracteriza por un tablero rectangular en el que piezas de diferentes
formas "tetrominos" descienden de manera continua, y el objetivo del
jugador es encajarlas de forma tal que se completen l√≠neas horizontales,
las cuales se eliminan para obtener puntuaci√≥n y evitar que el tablero
se llene.

El poroyecto consisti√≥ en implementar desde cero una versi√≥n funcional
de Tetris en el lenguaje de programaci√≥n Python, que sirviera como
entorno de pruebas para el agente. Sobre esta base, se incorporaron tres
algoritmos de b√∫squeda local: **Hill Climbing**, **Simulated Annealing**
y **Algoritmo Gen√©tico**, adaptados para la toma de decisiones en cada
jugada. El agente eval√∫a posibles movimientos y selecciona la opci√≥n que
maximiza su funci√≥n de evaluaci√≥n, considerando factores como l√≠neas
eliminadas, altura de la pila de piezas y huecos generados.

La elecci√≥n de Tetris como caso de estudio se debe a que combina
elementos de aleatoriedad, planificaci√≥n y optimizaci√≥n en tiempo real,
lo que lo convierte en un entorno ideal para experimentar con
estrategias de b√∫squeda local. Este informe presenta el proceso de
desarrollo, la metodolog√≠a empleada, los resultados obtenidos y un
an√°lisis comparativo del rendimiento de cada algoritmo.

![tetris](images/img_tetris.png)

___

## 2. **Marco Te√≥rico**

El presente proyecto se enmarca en el estudio de t√©cnicas de **b√∫squeda local** y **metaheur√≠sticas** aplicadas a la toma de decisiones en el juego Tetris. A continuaci√≥n, se describen los fundamentos te√≥ricos relevantes para la implementaci√≥n de los agentes, con especial √©nfasis en los principios, ventajas y limitaciones de los algoritmos seleccionados: Hill Climbing, Simulated Annealing y Algoritmo Gen√©tico.

---

### 2.1 **Descripci√≥n del juego**

Tetris es un videojuego de tipo puzzle en el que piezas compuestas por
bloques cuadrados denominadas tetrominos descienden desde la parte
superior de un tablero rectangular. El objetivo es mover y rotar estas
piezas para encajarlas de forma que se completen l√≠neas horizontales
continuas. Cada vez que se completa una l√≠nea, esta se elimina y se
otorgan puntos al jugador.

El juego finaliza cuando las piezas apiladas alcanzan la parte superior
del tablero, impidiendo la aparici√≥n de nuevas piezas. Durante la
partida, las piezas se generan de manera aleatoria y descienden de forma
continua, aumentando la velocidad a medida que avanza el juego y va
subiendo de nivel, lo que va aumentando su dificultad.

Existen siete tipos de tetromin√≥s, cada uno con una forma caracter√≠stica
identificada por una letra: I, O, T, L, J, S y Z. El jugador puede
desplazar las piezas hacia la izquierda o derecha, rotarlas y hacerlas
descender m√°s r√°pidamente, con el fin de colocarlas en la posici√≥n
√≥ptima para maximizar la puntuaci√≥n y evitar huecos innecesarios en la
estructura de bloques.

![Tetrominos](images/img_tetrominos.png)

En esta implementaci√≥n, se adopt√≥ un sistema de puntuaci√≥n cl√°sico que
otorga diferentes cantidades de puntos seg√∫n el n√∫mero de l√≠neas
eliminadas de forma simult√°nea: una l√≠nea (singles), dos (doubles), tres
(triples) o cuatro (tetrises).

---

### 2.2 **Objetivos del Juego**

El objetivo principal del Tetris, tanto en la versi√≥n tradicional, como
en la implementada en este proyecto, es maximizar la puntuaci√≥n e ir
avanzando de nivel, evitando que el tablero se llene.

Por lo tanto el agente debe colocar las piezas de forma estrat√©gica, con
el fin de completar l√≠neas horizontales que se eliminan de manera
autom√°tica.

El objetivo se desenglosa con el siguiente puntaje:

- Singles: 1 l√≠neas eliminada tiene el valor de 100 puntos

- Doubles: 2 l√≠neas eliminadas de manera simult√°nea tiene el valor de
  200 puntos

- Triples: 3 l√≠neas eliminadas de manera simult√°nea tiene el valor de
  400 puntos

- Tetrises: 4 l√≠neas eliminadas de manera simult√°nea tiene el valor de
  800 puntos

Por lo tanto, se busca priorizar la mayor cantidad de l√≠neas juntas para
eliminar de manera simult√°nea, y as√≠ sumar la mayor cantidad de puntos.
A su vez mantener un tablero estable, es decir evitar dejar huecos o
espacios dif√≠ciles de rellenar, tambi√©n minimizar la altura alcanzada
para reducir el riesgo de perder.

A medida que se va avanzando en el juego, es decir, se va subiendo de
nivel, el tiempo de ca√≠da de las piezas va aumentando, lo que va
dificultando a la hora de tomar decisiones.

---

### 2.3 B√∫squeda Local

Los algoritmos de b√∫squeda local exploran el espacio de soluciones movi√©ndose de un estado a otro a partir de peque√±as modificaciones (vecinos). Su objetivo es mejorar progresivamente una funci√≥n de evaluaci√≥n.

Sus caracter√≠sticas principales son:

- No requieren explorar todo el espacio de estados.  
- Funcionan bien en dominios grandes o continuos.  
- Pueden estancarse en √≥ptimos locales.

Debido a que Tetris requiere tomar decisiones r√°pidas y con informaci√≥n incompleta, la b√∫squeda local es un enfoque adecuado y ampliamente utilizado en la literatura.

---

### 2.4 Hill Climbing

Hill Climbing es un algoritmo de b√∫squeda local que avanza de manera iterativa hacia estados que presentan una mejora respecto del estado actual, de acuerdo con una funci√≥n de evaluaci√≥n previamente definida. Su principio fundamental consiste en seleccionar, dentro del conjunto de estados vecinos, aquel que maximiza (o minimiza) la heur√≠stica utilizada. Es un m√©todo determinista, de bajo costo computacional y ampliamente aplicado en problemas donde es necesario tomar decisiones r√°pidas.

En el contexto del juego Tetris, los vecinos pueden interpretarse como las distintas colocaciones posibles de la pieza actual (combinaciones de posiciones y rotaciones v√°lidas). El algoritmo eval√∫a cada una de estas configuraciones mediante una heur√≠stica que estima la calidad del tablero resultante y elige la mejor alternativa disponible.

Si bien Hill Climbing es eficiente y f√°cil de implementar, presenta limitaciones importantes. Debido a que solo acepta movimientos que mejoran el estado presente, puede quedar atrapado en **√≥ptimos locales**, mesetas o crestas del paisaje heur√≠stico. En Tetris, esto implica que decisiones localmente convenientes ‚Äîcomo reducir la altura inmediata del tablero o evitar un hueco puntual‚Äî pueden conducir a configuraciones desfavorables a futuro. Esto sucede especialmente en un entorno din√°mico y altamente no lineal como el del Tetris, donde una buena jugada ‚Äúlocal‚Äù no necesariamente implica un buen desempe√±o a largo plazo.

A pesar de estas limitaciones, Hill Climbing resulta adecuado como base comparativa, dado que ofrece una l√≠nea de referencia eficiente contra la cual evaluar m√©todos de b√∫squeda m√°s complejos.

---

### 2.5 Simulated Annealing (SA)

Simulated Annealing (SA) es un algoritmo de b√∫squeda local estoc√°stico inspirado en el proceso f√≠sico de recocido de metales, donde un material se calienta y luego se enfr√≠a de manera gradual hasta alcanzar un estado estable de m√≠nima energ√≠a. En su adaptaci√≥n al √°mbito computacional, el algoritmo permite aceptar movimientos que empeoran la funci√≥n de evaluaci√≥n con una probabilidad controlada por un par√°metro denominado temperatura. Este mecanismo introduce exploraci√≥n en la b√∫squeda y evita que el proceso quede atrapado en √≥ptimos locales.

El funcionamiento b√°sico del algoritmo consiste en partir de un estado inicial y generar, en cada iteraci√≥n, un estado vecino. Si el vecino mejora la funci√≥n de evaluaci√≥n, se acepta de manera determinista. Si es peor, se acepta con una probabilidad que decrece a medida que disminuye la temperatura, usualmente modelada por la expresi√≥n:


P(aceptar)=e
T
Œî
	‚Äã

donde:

Œî es la diferencia entre la evaluaci√≥n del nuevo estado y el actual, y 
ùëá es la temperatura vigente. 

Conforme el algoritmo avanza, la temperatura se reduce siguiendo un esquema de enfriamiento, lo que provoca una transici√≥n gradual desde un comportamiento altamente exploratorio hacia uno predominantemente explotador.

En el contexto del juego Tetris, los vecinos pueden interpretarse como las distintas jugadas posibles para la pieza actual, es decir, las combinaciones de rotaciones y posiciones v√°lidas que pueden producirse al colocarla en el tablero. Simulated Annealing eval√∫a cada una de estas configuraciones seg√∫n una heur√≠stica definida y decide si debe adoptarlas o no considerando tanto su calidad objetiva como la temperatura del sistema.

La principal ventaja de SA respecto de m√©todos puramente deterministas, como Hill Climbing, es su capacidad de evitar quedar atrapado en √≥ptimos locales. Al permitir la aceptaci√≥n probabil√≠stica de jugadas desfavorables en las primeras etapas, el algoritmo puede escapar de configuraciones aparentemente buenas pero que conducen a situaciones negativas a largo plazo. Esto resulta especialmente relevante en Tetris, donde la estructura del tablero puede presentar m√∫ltiples ‚Äútrampas heur√≠sticas‚Äù: huecos inevitables, columnas muy altas o configuraciones que dificultan la futura colocaci√≥n de piezas.

No obstante, Simulated Annealing requiere un dise√±o adecuado de sus par√°metros ‚Äîcomo la temperatura inicial y la tasa de enfriamiento‚Äî para lograr un equilibrio entre exploraci√≥n y explotaci√≥n. A pesar de esta sensibilidad, constituye una t√©cnica robusta para entornos din√°micos como Tetris, donde la incertidumbre y la necesidad de adaptaci√≥n continua hacen valiosa la capacidad de evaluar movimientos sub√≥ptimos de manera controlada.

---

### 2.6 Algoritmos Gen√©ticos (GA)

Los Algoritmos Gen√©ticos son m√©todos de optimizaci√≥n inspirados en los principios de la evoluci√≥n biol√≥gica, particularmente en la selecci√≥n natural, recombinaci√≥n y mutaci√≥n. Su objetivo es evolucionar una poblaci√≥n de soluciones candidatas hacia configuraciones cada vez m√°s aptas seg√∫n una funci√≥n de evaluaci√≥n. A diferencia de los algoritmos puramente locales, como Hill Climbing o Simulated Annealing, los GA operan sobre un conjunto de soluciones simult√°neamente, lo que mejora la exploraci√≥n del espacio de b√∫squeda y reduce la probabilidad de quedar atrapados en √≥ptimos locales.

En el contexto de Tetris, cada individuo de la poblaci√≥n puede representarse como una posible colocaci√≥n de la pieza actual (posici√≥n y rotaci√≥n) o, en variantes m√°s amplias, como secuencias de jugadas futuras. La funci√≥n de fitness eval√∫a cada individuo estimando la calidad del tablero resultante mediante una heur√≠stica que considera factores como:

- l√≠neas eliminadas,
- alturas m√°ximas,
- huecos generados,
- uniformidad de la superficie.

A partir de esta poblaci√≥n inicial, el GA aplica operadores evolutivos:

- **Selecci√≥n:** elige las configuraciones m√°s prometedoras, favoreciendo aquellas con mayor fitness.
- **Crossover:** combina dos individuos para generar nuevos candidatos que heredan caracter√≠sticas de ambos, lo cual promueve la exploraci√≥n estructurada del espacio.
- **Mutaci√≥n:** introduce cambios aleatorios en un individuo, aportando diversidad gen√©tica y evitando la convergencia prematura.

La naturaleza poblacional de los Algoritmos Gen√©ticos ofrece ventajas significativas para un juego como Tetris, donde la estructura del espacio heur√≠stico es altamente irregular y el impacto de cada jugada puede variar seg√∫n futuros estados del tablero. Al explorar m√∫ltiples alternativas en paralelo y mantener diversidad durante el proceso evolutivo, estos algoritmos son capaces de detectar jugadas que heur√≠sticas puramente locales pasar√≠an por alto.

Si bien los GA suelen requerir un mayor costo computacional y un ajuste cuidadoso de par√°metros (tama√±o de poblaci√≥n, probabilidad de cruce y mutaci√≥n, m√©todo de selecci√≥n), proporcionan una capacidad de b√∫squeda m√°s global y flexible. Por ello, constituyen un enfoque adecuado para evaluar estrategias en un entorno din√°mico e impredecible como Tetris, y permiten contrastar su desempe√±o frente a los m√©todos locales tradicionales.

___ 

## **Cuadro Comparativo entre algoritmos de b√∫squeda local aplicados**

| Par√°metro                | Hill Climbing                                                                 | Simulated Annealing                                                                 | Algoritmo Gen√©tico                                                                 |
|---------------------------|-------------------------------------------------------------------------------|-------------------------------------------------------------------------------------|------------------------------------------------------------------------------------|
| **Tipo de b√∫squeda**      | B√∫squeda local determin√≠stica: siempre elige la mejor opci√≥n inmediata        | B√∫squeda local probabil√≠stica: permite aceptar soluciones peores al inicio, simulando el enfriamiento de metales | B√∫squeda poblacional inspirada en la evoluci√≥n biol√≥gica: trabaja con una poblaci√≥n de soluciones que evolucionan |
| **Capacidad de escapar de √≥ptimos locales** | Baja: se queda atrapado si no hay vecinos mejores                          | Alta: puede aceptar soluciones peores para escapar de √≥ptimos locales               | Alta: la diversidad gen√©tica permite explorar m√∫ltiples regiones del espacio de b√∫squeda |
| **Exploraci√≥n vs explotaci√≥n** | Explotaci√≥n fuerte: enfocado solo en mejorar                               | Equilibrio controlado por la temperatura: m√°s exploraci√≥n al principio, m√°s explotaci√≥n al final | Alta exploraci√≥n: combina cruce y mutaci√≥n para generar variedad                    |
| **Uso de aleatoriedad**   | M√≠nimo: solo si se elige aleatoriamente entre vecinos iguales                 | Moderado: usa aleatoriedad para seleccionar vecinos y aceptar soluciones peores     | Alto: selecci√≥n, cruce y mutaci√≥n son procesos estoc√°sticos                         |
| **Dependencia de par√°metros** | Baja: solo depende de la funci√≥n heur√≠stica                                | Media: necesita definir temperatura inicial, tasa de enfriamiento y criterio de parada | Alta: muchos par√°metros influyen (tama√±o de poblaci√≥n, tasas de mutaci√≥n/cruce, elitismo, etc.) |
| **Costo computacional**   | Bajo: r√°pido, simple, apto para decisiones en tiempo real                     | Medio: m√°s costoso por evaluar m√∫ltiples vecinos y usar funciones probabil√≠sticas   | Alto: eval√∫a m√∫ltiples soluciones por generaci√≥n y realiza operaciones gen√©ticas     |
| **Aplicabilidad en tiempo real** | Alta: ideal para entornos con decisiones r√°pidas como Tetris             | Media: puede adaptarse, pero necesita buen ajuste de par√°metros para ser √°gil       | Baja-Media: requiere optimizaci√≥n o simplificaci√≥n para usarse en tiempo real       |
| **Complejidad de implementaci√≥n** | Baja: se implementa f√°cilmente con pocos pasos                          | Media: requiere l√≥gica de temperatura, aceptaci√≥n probabil√≠stica y enfriamiento     | Alta: implica manejar estructuras de poblaci√≥n, operadores gen√©ticos y ciclos evolutivos |

___

## 3. **Dise√±o Experimental**

En esta secci√≥n se describen los aspectos t√©cnicos y las decisiones de implementaci√≥n adoptadas para el desarrollo de los tres agentes inteligentes (Hill Climbing, Simulated Annealing y Algoritmo Gen√©tico) aplicados al entorno del juego Tetris. Adem√°s, se detallan las representaciones internas utilizadas, la funci√≥n de evaluaci√≥n, los par√°metros configurados y las m√©tricas analizadas durante los experimentos.

---

### 3.1 Control experimental
Para llevar a cabo el an√°lisis comparativo de los tres algoritmos implementados, se utiliz√≥ una semilla aleatoria que garantiza la generaci√≥n de la misma secuencia de piezas para los tres algoritmos. Esta decisi√≥n se tom√≥ debido a que, en pruebas preliminares sin control de secuencia, los resultados obtenidos eran inconsistentes, lo que imped√≠a extraer conclusiones v√°lidas. Al utilizar la semilla, se asegura que cada algoritmo reciba las mismas piezas en el mismo orden, permitiendo una comparaci√≥n justa y precisa de su desempe√±o.

Para garantizar la reproducibilidad y la comparabilidad entre algoritmos, se utilizaron 15 semillas aleatorias. Cada semilla se us√≥ para realizar una ejecuci√≥n de cada uno de los tres algoritmos (Hill Climbing, Simulated Annealing y Algoritmo Gen√©tico). Es decir, para cada valor de semilla, los tres algoritmos enfrentaron exactamente la misma secuencia de piezas.

En cada ejecuci√≥n se generaron 400 piezas, lo que permite observar el desempe√±o de los agentes en partidas suficientemente largas como para que se manifieste su comportamiento estrat√©gico.

La generaci√≥n de piezas se realiz√≥ a trav√©s de un sistema de 7-bag, que es el mecanismo est√°ndar en Tetris moderno. En este sistema, las siete piezas posibles se agrupan en una ‚Äúbolsa‚Äù y se ordenan de forma aleatoria. Cuando una bolsa se vac√≠a, se crea una nueva y se la vuelve a mezclar. Para asegurar que la secuencia generada fuera id√©ntica para los tres algoritmos dentro de la misma iteraci√≥n, se emple√≥: random.seed(semilla)

Cada vez que se inicia una nueva bolsa, la mezcla se ve determinada por la semilla global de la ejecuci√≥n. Esto permite que:

1. Cada iteraci√≥n del experimento produzca una secuencia √∫nica, pero reproducible.

2. Los tres algoritmos compitan bajo exactamente las mismas condiciones, eliminando la variabilidad externa debida al azar.

Para evaluar el rendimiento y las decisiones de los algoritmos, se seleccionaron las siguientes m√©tricas:

* Cantidad de singles, dobles, triples y tetrises: Permite analizar la eficiencia en la eliminaci√≥n de l√≠neas y la capacidad de formar combinaciones √≥ptimas.

* Nivel alcanzado por algoritmo: Indica la progresi√≥n del juego y la habilidad del algoritmo para sostenerse en niveles m√°s avanzados.

* Puntaje obtenido: Refleja el desempe√±o global del algoritmo en funci√≥n de las reglas de puntuaci√≥n del juego.

* Tiempo promedio de toma de decisi√≥n: Eval√∫a la eficiencia computacional y la rapidez con la que el algoritmo selecciona la mejor acci√≥n posible.

* Consistencia por algoritmo: Mide la estabilidad del rendimiento entre distintas ejecuciones del mismo algoritmo bajo la misma secuencia de piezas.

* Cantidad de l√≠neas eliminadas por piezas colocadas: Proporciona un indicador de eficiencia en la colocaci√≥n de piezas y en la optimizaci√≥n del espacio de juego.

Estas m√©tricas permiten un an√°lisis integral, considerando tanto el desempe√±o cuantitativo (puntaje, l√≠neas eliminadas) como cualitativo (eficiencia de decisiones y consistencia), proporcionando una visi√≥n completa sobre las fortalezas y debilidades de cada algoritmo.

---

### 3.2 Simulacion del entorno, tiempo y procesamiento de piezas

En el simulador utilizado, el tiempo no constituye una restricci√≥n operativa relevante para los agentes. Aunque en el Tetris original el descenso de las piezas se acelera a medida que aumentan los niveles, en nuestra implementaci√≥n las decisiones se toman de manera instant√°nea, dado que los algoritmos de b√∫squeda empleados (Hill Climbing, Simulated Annealing y Algoritmo Gen√©tico) responden en tiempos muy reducidos. Como resultado, los cambios de velocidad del juego no afectan la capacidad de exploraci√≥n ni la calidad de las decisiones.

El proceso de decisi√≥n se estructura de forma secuencial: cada vez que aparece una pieza nueva, el algoritmo correspondiente se ejecuta nuevamente para evaluar todas las posiciones y rotaciones v√°lidas. Una vez seleccionada la mejor acci√≥n para la pieza actual, el movimiento se aplica al tablero y se genera la siguiente pieza. De esta manera, los algoritmos se ejecutan una vez por cada pieza a colocar, simulando el avance natural del juego.

---

### 3.3 Representaci√≥n del entorno

El entorno de Tetris fue modelado como una matriz de 22 filas por 10 columnas, donde las 2 primeras filas se utilizan para posicionar las piezas cuando aparecen por primera vez en el tablero por encima de la l√≠nea skyline, donde cada celda puede encontrarse ocupada o libre. Las piezas corresponden a los siete tetromin√≥s est√°ndar (I, O, T, L, J, S, Z), cada uno implementado con todas sus rotaciones v√°lidas y con su color caracter√≠stico, siguiendo la convenci√≥n del Tetris cl√°sico.

<div align="center">
    <img src="images/tablero.png" alt="Tablero del juego Tetris" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 1: Tablero del juego.
    </p>
</div>

---

### 3.4 Generaci√≥n y comportamiento de las piezas

Las piezas se generan utilizando el sistema 7-Bag, en el que cada conjunto contiene exactamente una copia de cada tetromin√≥ y se reordena de manera aleatoria cada vez que la bolsa se vac√≠a. Todas las piezas aparecen en orientaci√≥n North Facing y ubicadas de forma centrada respecto del tablero, respetando las reglas del Tetris cl√°sico.

Durante el turno de una pieza activa, esta puede:

 * Moverse horizontalmente una celda por acci√≥n,

* Rotarse en incrementos de 90¬∞,

Adem√°s, se implement√≥ la pieza fantasma (ghost piece), que indica la posici√≥n final de ca√≠da si la pieza se soltara en ese momento. Esta funcionalidad resulta √∫til para visualizar el entorno y para asistir a los algoritmos de toma de decisiones.

---

### 3.5 Niveles, objetivos y puntuaci√≥n

El juego inicia siempre en el nivel 1. Para avanzar de nivel se utiliza un sistema de objetivo fijo, donde el jugador debe eliminar 10 l√≠neas por nivel hasta alcanzar el nivel 15 (totalizando 150 l√≠neas). El nivel afecta √∫nicamente la velocidad de ca√≠da de las piezas.

La puntuaci√≥n del tablero se actualiza seg√∫n la cantidad de l√≠neas eliminadas simult√°neamente:

1 l√≠nea (Single): 100 puntos

2 l√≠neas (Double): 200 puntos

3 l√≠neas (Triple): 400 puntos

4 l√≠neas (Tetris): 800 puntos

En caso de que se eliminen m√°s de 4 lineas se toma el numero de l√≠neas eliminadas separadas en bloques de a 4, por ejemplo, si el algoritmo elimina 7 lineas horizontales al colocar un pieza entonces estaria generando un tetris m√°s un triple, obteniendo un total de 1200 ptos.

---

### 3.6 Condici√≥n de finalizaci√≥n

La partida finaliza cuando una pieza queda fijada en la parte superior del tablero, es decir, cuando se produce un top out.

<div align="center">
    <img src="images/top_out.png" alt="Finalizacion de juego por top out" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 2: Finalizaci√≥n de juego por top out.
    </p>
</div>

---

### 3.7 Representaci√≥n del estado y las piezas

El estado del juego se modela como la combinaci√≥n del tablero actual y la pieza activa. Cada movimiento v√°lido se genera aplicando todas las rotaciones posibles de la pieza y luego desliz√°ndola horizontalmente hasta posiciones legales.

Las piezas se modelan como listas de coordenadas que representan las celdas ocupadas por cada figura. Cada rotaci√≥n se define mediante una lista de coordenadas distinta, equivalente a aplicar una transformaci√≥n de rotaci√≥n sobre la figura original.

---

### 3.8 Funci√≥n de evaluaci√≥n

La funci√≥n heur√≠stica utilizada por los agentes eval√∫a cada estado posible del tablero seg√∫n cuatro caracter√≠sticas clave: la cantidad de l√≠neas eliminadas, la generaci√≥n de huecos, el desnivel entre columnas y la altura promedio de la estructura. Cada caracter√≠stica se pondera mediante un peso, cuyo valor determina la relevancia relativa que tendr√° dentro del c√°lculo de la calidad del estado.

La selecci√≥n de estos pesos responde a criterios estrat√©gicos del juego, a pruebas emp√≠ricas y, en el caso del Algoritmo Gen√©tico, al hecho de que dicho agente evoluciona sus decisiones a lo largo del tiempo. Para establecer valores iniciales coherentes, partimos de una base de pesos, propuesto por Pierre Dellacherie en ‚ÄúThe (Near) Perfect Tetris Bot‚Äù, del cual derivan la mayor√≠a de los agentes cl√°sicos de Tetris. Estos valores fueron luego ajustados para adaptarse a nuestra representaci√≥n del tablero y a las necesidades espec√≠ficas de cada algoritmo de b√∫squeda.

A continuaci√≥n, se detallan las razones de la eleccion de cada peso:

### 3.8.1 L√≠neas eliminadas

*Objetivo*: premiar las jugadas que producen limpieza del tablero.

En Hill Climbing y Simulated Annealing se asign√≥ un peso alto (3.5) porque eliminar l√≠neas es la principal forma de puntuar y evitar que el tablero colapse.

<div align="center">
    <img src="images/hc_explotacion.png" alt="Hill climbing explotacion" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 3: A√±goritmo Hill Climbing.
    </p>
</div>

En el Algoritmo Gen√©tico se redujo a 0.8 porque el GA explora combinaciones de piezas y, si la recompensa por l√≠neas es demasiado grande, el algoritmo converge r√°pido a soluciones sesgadas que s√≥lo priorizan limpiezas inmediatas y no construyen jugadas estables a largo plazo. La presi√≥n selectiva debe ser menor para permitir diversidad de estrategias.

<div align="center">
    <img src="images/ga_exploracion.png" alt="GA exploracion" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 4: Algoritmo Gen√©tico.
    </p>
</div>

### 3.8.2 Huecos

*Objetivo*: penalizar la creaci√≥n de huecos, ya que dificultan limpiezas futuras y suelen causar derrota.

Los huecos son la caracter√≠stica negativa m√°s costosa en Tetris; siempre deben penalizarse con fuerza.

En Hill climbing y simulated annealing se usa un peso muy alto (5) para evitar movimientos que creen huecos casi de manera absoluta.

<div align="center">
    <img src="images/sa_sin_huecos.png" alt="Sa minimizando huecos" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 5: Algoritmo Simulated Annealing minimizando huecos en partida.
    </p>
</div>

En GA se usa un valor medio-alto (3.5) para permitir que en generaciones tempranas el algoritmo explore configuraciones que podr√≠an ser √∫tiles aunque tengan huecos, evitando que la poblaci√≥n se estanque. Sin embargo, sigue siendo alto para evitar la finalizacion del juego al aceptar muchas pocisiones que generen huecos.

<div align="center">
    <img src="images/ga_huecos.png" alt="Ga huecos" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 6: Algoritmo gen√©tico.
    </p>
</div>

### 3.8.3 Desnivel

*Objetivo*: evitar que el tablero tenga picos o valles pronunciados.

En ambas versiones se mantuvo un peso moderado (0.5).

La raz√≥n es que el desnivel es importante, pero no tan decisivo como los huecos o la limpieza. Un desnivel alto suele impedir colocar futuras piezas pero a nivel estrategico permite resevar posiciones para piezas que encajan perfectamente y permiten eliminar mayor cantidad de lineas.Por eso se penaliza, pero no con extrema agresividad.

<div align="center">
    <img src="images/ga_desnivel.png" alt="desnivel" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
    	Figura 7: Desnivel en partida de algortimo gen√©tico.
    </p>
</div>

### 3.8.4 Altura promedio

*Objetivo*: evitar que la estructura crezca hacia arriba, dejando espacio para maniobrar.

En HC/SA se utiliza un peso m√°s alto (2) para castigar posiciones que elevan la torre r√°pidamente.

En GA el peso se reduce a 0.3, nuevamente para permitir mayor exploraci√≥n en generaciones tempranas y evitar que la altura excesiva elimine estrategias potencialmente √∫tiles antes de evolucionar.

La altura elevada aumenta el riesgo de perder, pero el GA necesita flexibilidad al inicio y no debe castigar demasiado este factor.

---

### 3.9 Especificaciones de implementacion de cada algoritmo

A continuacion se especifican los detalles de implementacion de cada algortimo.

### 3.9.1 Hill Climbing

El agente Hill Climbing genera todos los vecinos posibles de la pieza actual explorando cada combinaci√≥n v√°lida de columna y rotaci√≥n. Para cada vecino simula la ca√≠da de la pieza, actualiza el estado y eval√∫a el resultado mediante la heur√≠stica definida. Luego selecciona el vecino con mayor valor heur√≠stico; en caso de empate, elige aleatoriamente entre los mejores. Esta decisi√≥n se aplica al juego real y el proceso se repite pieza por pieza.

### 3.9.2 Simulated Annealing

Para cada pieza, el algoritmo genera previamente todas las combinaciones v√°lidas de posiciones y rotaciones posibles. Cada combinaci√≥n incluye la posici√≥n final en el tablero, la rotaci√≥n alcanzada y el puntaje calculado por la funci√≥n heur√≠stica. Este conjunto constituye el espacio de b√∫squeda sobre el cual opera el algoritmo.

El proceso comienza seleccionando de forma aleatoria uno de estos estados v√°lidos como estado inicial. Esta aleatoriedad evita sesgos en la elecci√≥n inicial y contribuye a una mayor diversidad en el comportamiento del agente entre distintas ejecuciones.

Un punto central del m√©todo es la temperatura inicial. En esta implementaci√≥n, la temperatura se calcula mediante una f√≥rmula que garantiza que un movimiento que empeora la heur√≠stica en 4 unidades tenga aproximadamente un 60% de probabilidad de ser aceptado. Esto da como resultado una temperatura inicial cercana a 7.575, lo que permite un grado significativo de exploraci√≥n en las primeras etapas del algoritmo.

En cada iteraci√≥n, el SA no considera todos los vecinos, sino que selecciona una muestra peque√±a y aleatoria de ellos. Concretamente, se toman hasta 3 vecinos aleatorios del conjunto total.

 Entre estos vecinos seleccionados, el algoritmo elige el que tiene el mejor valor heur√≠stico y lo considera como candidato a nuevo estado. Esta estrategia equilibra el costo computacional con la capacidad exploratoria, ya que reduce el n√∫mero de evaluaciones por iteraci√≥n sin perder diversidad.

Para decidir si el estado candidato se acepta o no, se aplica la regla de Metropolis. Si el estado candidato tiene un valor heur√≠stico mayor que el actual, se acepta siempre. Si en cambio es peor, se acepta con una probabilidad que depende tanto de la magnitud del empeoramiento como de la temperatura actual. Espec√≠ficamente, la probabilidad de aceptaci√≥n se calcula como 
ùëí
Œî
/
ùëá

donde

Œî: diferencia de heur√≠stica entre el nuevo estado y el actual

ùëá: temperatura en ese momento. 

Esto significa que, especialmente al inicio cuando la temperatura es alta, el algoritmo tiene m√°s libertad para explorar movimientos sub√≥ptimos.

La temperatura se actualiza en cada iteraci√≥n mediante un esquema de enfriamiento exponencial, utilizando un coeficiente de 0.95. Esto implica que la temperatura disminuye gradualmente, reduciendo la probabilidad de aceptar movimientos peores a medida que avanza el proceso. El algoritmo contin√∫a iterando hasta que la temperatura cae por debajo de 0.1 o hasta alcanzar un m√°ximo de 300 iteraciones, lo que ocurra primero. Estos l√≠mites garantizan que el tiempo de c√°lculo sea acotado y que el algoritmo converja a una soluci√≥n estable.

Finalmente, cuando el proceso concluye, el algoritmo devuelve la posici√≥n y rotaci√≥n que resultaron seleccionadas tras todo el proceso de exploraci√≥n y aceptaci√≥n probabil√≠stica. Esa configuraci√≥n se utiliza entonces para colocar la pieza en el tablero.

### 3.9.3 Genetic Algorithm

Para el agente basado en Algoritmo Gen√©tico (GA), cada individuo de la poblaci√≥n representa una combinaci√≥n posible de movimiento para la pieza actual del juego Tetris, definida como una tupla (posici√≥n, rotaci√≥n, fitness). A partir del conjunto completo de combinaciones v√°lidas, el algoritmo inicializa una poblaci√≥n de tama√±o 20 (o menor en caso de que existan menos combinaciones disponibles en ese turno).

### **Inicializacion**

* Se generan todas las combinaciones posibles v√°lidas (pos, rot, fit) para la pieza actual.

* Se seleccionan 20 individuos iniciales de manera aleatoria para formar la poblaci√≥n.

* Se define un tama√±o de √©lite equivalente al 10% de la poblaci√≥n (elite_size = 2).

### **Seleccion: M√©todo de Torneo**

En cada iteraci√≥n, la poblaci√≥n se divide aleatoriamente en grupos de tama√±o:

2 individuos si la poblaci√≥n es par

3 individuos si es impar

En cada grupo se selecciona el individuo con mayor fitness. En caso de empate, se utiliza como criterio secundario el individuo cuyo valor y (posicion) sea el m√°s bajo en el tablero, y si persiste el empate, la selecci√≥n se resuelve de manera aleatoria.
Este proceso genera el conjunto de individuos m√°s aptos que participar√°n del cruce.

### **Cruce**

Se aplica un cruzamiento completo pareado entre todos los individuos seleccionados:
cada individuo se cruza con todos los dem√°s salvo consigo mismo.

El mecanismo de cruce intercambia atributos de la siguiente forma:

Con probabilidad menor a 0.5:

* La rotaci√≥n del hijo proviene del padre 1

* La posici√≥n del hijo proviene del padre 2

De lo contrario:

* La rotaci√≥n proviene del padre 2

* La posici√≥n proviene del padre 1

Una vez generada la tupla (pos, rot), se busca su fitness correspondiente en el conjunto de combinaciones v√°lidas. Si el hijo no corresponde a un estado permitido, se reemplaza por uno de los padres para evitar p√©rdida de diversidad.

### **Mutaci√≥n**

Tras el cruce, cada individuo tiene una probabilidad de 0.5 de sufrir una mutaci√≥n en su rotaci√≥n.

El proceso consiste en:

1. Seleccionar una rotaci√≥n aleatoria entre las posibles para la pieza actual.

2. Buscar si (pos, rot_mutada) es una combinaci√≥n v√°lida.

3. Si existen m√∫ltiples combinaciones v√°lidas con esa rotaci√≥n, se elige una al azar para mantener diversidad.

Los individuos mutados se a√±aden a la poblaci√≥n.

### **Elitismo y generaci√≥n de la nueva poblaci√≥n**

Luego del cruce y la mutaci√≥n:

1. Se seleccionan los 2 mejores individuos de la poblaci√≥n actual (√©lite).

2. Se combinan con la descendencia generada, que es ordenada por fitness y truncada para mantener el mismo tama√±o poblacional.

3. La nueva poblaci√≥n queda formada por elite + descendencia.

___

## 4. **An√°lisis y discusi√≥n de resultados**

### Singles, doubles, triples y tetrises (gr√°fico1)

Adem√°s de reportar los promedios de l√≠neas eliminadas para cada tipo de eliminaci√≥n (Singles, Doubles, Triples y Tetrises), se incluy√≥ la desviaci√≥n est√°ndar correspondiente a cada m√©trica.
La desviaci√≥n est√°ndar permite evaluar la estabilidad del rendimiento de cada algoritmo: valores bajos indican comportamientos consistentes entre partidas, mientras que valores altos reflejan una mayor variabilidad. Para calcularla, se tomaron las 15 repeticiones realizadas por cada algoritmo sobre una secuencia de 400 piezas y se comput√≥ la desviaci√≥n est√°ndar por tipo de eliminaci√≥n agrupando los resultados por algoritmo.

Finalmente, en la figura correspondiente se incorporaron barras de error sobre cada barra, representando gr√°ficamente estas desviaciones. Esto permite una comparaci√≥n m√°s rigurosa entre algoritmos, ya que no solo se observa la media sino tambi√©n la dispersi√≥n de los resultados.

<div align="center">
    <img src="images/singles_dobles_triples.png" alt="Singles, doubles, triples" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 8: Diagrama de barras con promedio de lineas eliminadas para cada tipo de eliminaci√≥n.
    </p>
</div>

En la figura 8 puede observarse que Hill Climbing es el algoritmo que m√°s singles completa en promedio. Esto es consistente con su naturaleza determinista y fuertemente explotativa: en cada decisi√≥n selecciona la opci√≥n que maximiza la ganancia inmediata, lo cual conduce a una estrategia que elimina l√≠neas con mayor frecuencia pero de forma individual, sin priorizar la acumulaci√≥n necesaria para eliminaciones m√∫ltiples.

En contraste, el algoritmo Gen√©tico presenta mayores valores en doubles, triples y tetrises. Esto se alinea con su comportamiento explorativo: al trabajar con una poblaci√≥n de soluciones y operadores estoc√°sticos como mutaci√≥n y cruce, el agente tiende a permitir configuraciones m√°s diversas y con mayor altura, lo que favorece la generaci√≥n de eliminaciones m√∫ltiples cuando se estabiliza la estructura.

Por otro lado, Simulated Annealing muestra la mayor variabilidad, especialmente en el caso de singles. Esto es esperable debido a su mecanismo probabil√≠stico y a la influencia directa de la curva de enfriamiento: en etapas con temperaturas m√°s altas puede aceptar peores movimientos, lo que provoca diferencias significativas entre partidas. Esta misma caracter√≠stica afecta tambi√©n a doubles, triples y tetrises, ya que su comportamiento oscila entre fases explorativas y explotativas. En consecuencia, algunas ejecuciones logran secuencias de colocaci√≥n m√°s eficientes, mientras que otras se ven afectadas por decisiones sub√≥ptimas aceptadas en etapas tempranas.

***

### Nivel alcanzado vs puntaje obtenido

Para poder evaluar la eficiencia en la toma de decisiones y el desempe√±o de cada algoritmo hemos construido un gr√°fico de dispersi√≥n con barras de error.
En la figura 9 se representan los resultados obtenidos tras ejecutar cada algoritmo en un total de 15 partidas de 400 piezas cada una:

El eje Y (vertical) muestra el Puntaje Obtenido (promedio), indicando la calidad de la soluci√≥n encontrada (mejor desempe√±o).

El eje X (horizontal) muestra el Nivel Alcanzado (promedio), que es una m√©trica de la habilidad del agente para sobrevivir y planificar a largo plazo.

Adem√°s, se incorporaron barras de error (desviaciones est√°ndar) en ambos ejes. Estas barras nos permiten visualizar la variabilidad o consistencia de cada algoritmo, ofreciendo un panorama m√°s amplio de los resultados obtenidos.

<div align="center">
    <img src="images/nivel_vs_puntaje.png" alt="resultado nivel vs puntaje" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 9: Gr√°fico de dispersion de nivel alcanzado vs puntaje obtenido.
    </p>
</div>

En la figura 9 se puede observar como el algortimo Hill Climbing (punto azul) presenta un desempe√±o superior, destac√°ndose en tres aspectos clave:

* Mayor Puntaje y Nivel Alcanzado: logra el promedio de puntaje m√°s alto (aproximadamente 128.000) y el promedio de nivel m√°s alto (aproximadamente 15.5).

* Menor Variabilidad: Sus barras de error son notablemente m√°s cortas en comparaci√≥n con los otros dos algoritmos, lo que indica una mayor consistencia en sus resultados a lo largo de las 15 partidas.

Este resultado se corresponde con la naturaleza greedy del Hill Climbing, que prioriza la explotaci√≥n inmediata de la mejor opci√≥n local. Al analizar y ver la toma decisiones del algoritmo durante cada jugada se podria decir que estos resultados se corresponden con el hecho de que al limpiar m√°s lineas, al algoritmo logra con efectividad mantener el tablero despejado por lo que la probabilidad de que una partida termine por tablero completo es muy baja ya que siempre busca eliminar la mayor cantidad de lineas lo que le permite sobrevivir y, por ende, acumular mayor puntaje y alcanzar niveles m√°s altos de forma sostenida.

Por su parte, los algoritmos genetico (punto rojo) y simulated annealing (punto verde) al ser m√°s explorativos que el anterior pueden presentar mayor variablidad en los resultados. Esta mayor variabilidad es un efecto directo de su naturaleza explorativa. A diferencia del Hill Climbing, estos algoritmos est√°n dise√±ados para evitar quedar atrapados en √≥ptimos locales, lo que conlleva a dos situaciones:

1. Exploraci√≥n Exitosa: En algunas partidas, que se ven favorecidas por orden en el que se generan las piezas, la exploraci√≥n les permite encontrar configuraciones de tablero o estrategias que conducen a un buen desempe√±o.

2. Exploraci√≥n Fallida: En otros casos, la inclinaci√≥n hacia la exploraci√≥n de estados no √≥ptimos o la aceptaci√≥n de movimientos "peores" (especialmente al inicio de la partida en el Simulated Annealing) puede llevarlos prematuramente a una configuraci√≥n de tablero en la cual es dificil limpiar lineas. Esto resulta en partidas que terminan r√°pidamente por tablero completo y con puntajes muy bajos, lo que adem√°s aumenta dr√°sticamente la desviaci√≥n est√°ndar general.

---

### Puntaje total por algoritmo

Para complementar el an√°lisis anterior, se construy√≥ un diagrama de caja que permite visualizar la distribuci√≥n completa de los puntajes obtenidos por cada algoritmo implementado en un total de 15 partidas de 400 piezas jugadas. Este tipo de gr√°fico nos permite entender la dispersi√≥n, tendencia central, y la presencia de valores at√≠picos en los resultados.

Al analizar este gr√°fico, podremos evaluar no solo el rendimiento medio (mediana) de cada algoritmo, sino tambi√©n su consistencia (qu√© tan estrecha es la caja) y su rango de resultados (la longitud total de los bigotes).

<div align="center">
    <img src="images/puntaje_total.png" alt="Resultado puntaje total" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 10: Diagrama de caja con puntaje total.
    </p>
</div>

En la figura 10 se puede observar como el algoritmo Hill climbing es el mas consistente respaldando los resultados anteriores, m√°s especificamente:

* Su caja es la m√°s estrecha y est√° ubicada en el nivel de puntajes m√°s alto (la mediana se encuentra cerca de $\text{138.000}$).
* El 50% central de sus partidas se concentra en un rango muy peque√±o, lo que prueba su alta consistencia.
* El rango peque√±o de sus bigotes, junto con la estrechez de la caja, confirma que su estrategia greedy de explotaci√≥n constante le permite mantener un alto rendimiento.

Por su parte el Simulated annealing, es el segundo mejor en cuanto a la tendencia central de sus resultados, pero presenta la mayor dispersi√≥n:

* La l√≠nea de su mediana se ubica aproximadamente en $\text{128.000}$, siendo superior a la mediana del Algoritmo Gen√©tico. Esto sugiere que, en el caso promedio (percentil 50), el SA logr√≥ un mejor puntaje que el GA.
* El tener una mediana alta combinada con gran dispersi√≥n indica que el SA logra altos puntajes cuando su exploraci√≥n es exitosa, pero su riesgo de terminar una partida r√°pido por puntaje muy bajo es mucho mayor que en el GA.

Para  finalizar, el algortimo gen√©tico se encuentra en tercer lugar en t√©rminos de tendencia central:

* Su mediana se ubica cerca de $\text{110.000}$, siendo la m√°s baja de los tres. Esto significa que el 50% central de sus resultados es consistentemente menor que el de los otros dos algoritmos.
* Aunque es menos consistente que el HC, su rango de resultados es m√°s acotado que el del SA. Sus resultados m√≠nimos son significativamente mejores que los m√≠nimos del SA, por lo que demuestra tener una base de rendimiento m√°s segura que el Simulated Annealing, a pesar de que su mediana m√°s baja.
* Al observar el bigote superior, se evidencia que el Algoritmo Gen√©tico es capaz de alcanzar puntajes m√°ximos comparables a los obtenidos por el Hill Climbing y el Simulated Annealing (superiores a $\text{140.000}$).

Este alto potencial sugiere que, en ciertas instancias, la estrategia evolutiva del algoritmo logra identificar combinaciones de pesos o jugadas que resultan en la limpieza masiva de l√≠neas. Es probable que la ejecuci√≥n exitosa de Tetrises y Triples, las jugadas que otorgan mayor puntaje, sea lo que impulsa estos resultados m√°ximos, indicando que la exploraci√≥n del GA es capaz de encontrar estrategias √≥ptimas en su mejor caso.

---

### Puntaje obtenido vs Tiempo de toma de decisi√≥n

Para evaluar la eficiencia operativa de los tres algoritmos, construimos un gr√°fico de dispersi√≥n con barras de error (gr√°fico 4) que relaciona el puntaje obtenido (calidad de la decisi√≥n) con el tiempo promedio invertido en cada toma de decisi√≥n (velocidad de la decisi√≥n), el cual nos permite analizar qu√© algoritmo logra el mejor compromiso entre velocidad y desempe√±o.

La gr√°fica representa los resultados de un total de 15 partidas de 400 piezas jugadas por cada algoritmo, donde:

El Eje Y (Puntaje Obtenido - promedio) mide la calidad de la soluci√≥n (el desempe√±o general del agente).

El Eje X (Tiempo Promedio de Decisi√≥n en segundos) mide la velocidad con la que el algoritmo selecciona el siguiente movimiento.

Las barras de error (desviaciones est√°ndar) en ambos ejes nos permiten analizar la consistencia del algoritmo tanto en el desempe√±o del puntaje como en la estabilidad de su velocidad de procesamiento.

<div align="center">
    <img src="images/puntaje_vs_tiempoDecision.png" alt="Puntaje vs tiempo decision" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 11: Gr√°fico de dispersi√≥n de puntaje vs tiempo de decisi√≥n.
    </p>
</div>

En el figura 11 podemos observar que el HC (azul) es el algoritmo que consigue el mejor resultado en la recion tiempo de decision - puntaje obtenido y esto es esperable ya que si bien analiza todos los vecinos y escoge el que devuelve mejores resultados, no realiza c√°lculos probabil√≠sticos o poblacionales, lo que resulta en una baja complejidad computacional por paso. 

Por otro lado, tanto el Simulated Annealing (SA) como el algoritmo Gen√©tico (GA) incurren en un mayor tiempo de decisi√≥n debido a la naturaleza de sus procesos exploratorios, lo que los penaliza en el eje del tiempo de decision:

1. Simulated Annealing (verde):
*  Aunque tiene una estructura de b√∫squeda similar al HC, el SA a√±ade el c√°lculo probabil√≠stico (la funci√≥n de aceptaci√≥n dependiente de la 'temperatura') y la generaci√≥n de n√∫meros aleatorios en cada paso. Esta peque√±a sobrecarga se traduce en un tiempo de decisi√≥n m√°s largo.

2. Genetic (rojo):

* Presenta la mayor latencia, con un tiempo de decisi√≥n promedio de casi el doble que el HC y su puntaje promedio es comparable al del SA.

El tiempo de decisi√≥n elevado es resultado directo de su alta complejidad algor√≠tmica. En cada paso, el GA debe:

1. Evaluar a m√∫ltiples individuos (la poblaci√≥n).

2. Ejecutar procesos de selecci√≥n y cruce (crossover).

3. Aplicar mutaci√≥n a los individuos.

---

### Consistencia por algortimo

Para poder tener una estadistica pura de la variabilidad de cada algortimo con respecto al puntaje vs lineas eliminadas, presentamos un gr√°fico de dispersi√≥n que utiliza el Coeficiente de Variaci√≥n (CV) en ambos ejes.

- Interpretacion de los ejes:

Eje X (CV Puntaje - %): Mide la variabilidad en los puntajes obtenidos.
* Un CV de Puntaje bajo indica que las diferencias entre el puntaje m√°s alto y el m√°s bajo de las partidas es peque√±a en relaci√≥n con el puntaje promedio.

Eje Y (CV L√≠neas Eliminadas - %): Mide la variabilidad en la cantidad de l√≠neas eliminadas en las partidas.
* Un CV de L√≠neas bajo indica que el n√∫mero de l√≠neas que el algoritmo logra eliminar es muy similar en cada partida.

Tomamos la relacion entre el puntaje obtenido en cada partida y la cantidad de lineas eliminadas porque esto nos permite entender como se manifiestan las estrategias de exploraci√≥n y explotacion en la estabilidad de los resultados 

* Un algoritmo que prioriza la explotaci√≥n de la mejor soluci√≥n inmediata tender√° a repetir patrones de juego exitosos, lo que se traduce en baja variabilidad en el puntaje y en las l√≠neas eliminadas (punto cercano al origen).

* Un algoritmo que prioriza la exploraci√≥n tomar√° riesgos en algunas partidas que fallar√°n, pero tendr√° √©xito en otras. Esto resulta en una alta variabilidad en ambas m√©tricas (punto lejano al origen).

<div align="center">
    <img src="images/consistencia.png" alt="Consistencia" style="max-width: 70%; height: auto; border: 1px solid #ccc;">
    <p style="font-style: italic; font-size: 0.9em; margin-top: 5px;">
        Figura 12: Consistencia.
    </p>
</div>
  
Hill climbing: Se ubica m√°s cerca del origen, confirmando su naturaleza de Explotaci√≥n. Su b√∫squeda greedy constante produce resultados muy estables tanto en la cantidad de l√≠neas que limpia como en el puntaje final.

Genetic: Muestra una variabilidad moderada en ambos ejes. Su CV en l√≠neas eliminadas es relativamente bajo, pero su CV de puntaje es alto, lo que sugiere que su estrategia de juego (l√≠neas eliminadas) es m√°s estable que su resultado final (puntaje).

Simulated annealing: Se ubica en el punto m√°s alejado del origen, lo que confirma su alta tendencia a la Exploraci√≥n. Esta variabilidad es el precio de su b√∫squeda global: en ocasiones encuentra soluciones √≥ptimas, pero en muchas otras termina la partida r√°pidamente con resultados err√°ticos.

___

## 5. Conclusion

Bas√°ndonos en las m√©tricas definidas, concluimos que el algoritmo Hill Climbing demuestra ser el agente de IA superior para la tarea de jugar al Tetris, esto no solo se refleja en el desempe√±o bruto, sino tambi√©n en su eficiencia y estabilidad, los cuales son aspectos cr√≠ticos para cualquier agente de toma de decisiones en tiempo real. Su prioridad en la explotaci√≥n le permiti√≥ maximizar las jugadas de limpieza de l√≠neas (singles y doubles) por encima de tetrises y triples, manteniendo el tablero despejado y asegurando la supervivencia a largo plazo, lo que a su vez le permiti√≥ conseguir mejor puntaje promedio entre los tres algoritmos. Adem√°s, demostr√≥ ser el agente m√°s confiable y predecible, minimizando el riesgo de fallos graves que se observaron en los algoritmos exploratorios. 

Si bien los algoritmos exploratorios (GA y SA) pueden ejecutar jugadas de alto valor (Tetrises y triples), su constante b√∫squeda de soluciones globales comprometi√≥ el espacio del tablero, llevando a un mayor n√∫mero de partidas terminadas por top out prematuramente. Por lo que la estrategia de Explotaci√≥n local y consistente del Hill Climbing se alinea de manera m√°s efectiva con el objetivo central del juego Tetris: supervivencia a largo plazo y limpieza eficiente del tablero, demostrando mejor relaci√≥n entre rendimiento, velocidad y estabilidad.

Finalmente, dejamos planteadas dos modificaciones que se podr√≠an implementar a futuro con el fin de mejorar el rendimiento, eficiencia y toma de decisiones de los agentes, y que no se desarrollaron en el presente proyecto:

### 1. Implementacion de lookahead:

Una limitaci√≥n del dise√±o actual es que los agentes toman decisiones bas√°ndose √∫nicamente en la pieza actual y el estado inmediato del tablero, por lo que se podr√≠a introducir un mecanismo de b√∫squeda anticipada (Lookahead) que permita a los algoritmos evaluar las consecuencias de sus movimientos considerando la siguiente pieza. Lo que podria reducir la variabilidad de los algoritmos exploratorios (Gen√©tico y Simulated Annealing), ya que una mejor planificaci√≥n podr√≠a disminuir la probabilidad de fallos tempranos por acumulaci√≥n de piezas.

### 2. Optimizacion de pesos en la funcion heur√≠stica

Actualmente, los pesos utilizados en la funci√≥n heur√≠stica se han ajustado de manera emp√≠rica, por lo que el rendimiento del agente est√° limitado por la calidad de estos valores. Podriamos usar el Algoritmo Gen√©tico, que es un algoritmo de optimizacion, para ajustar autom√°ticamente los pesos de la funci√≥n heur√≠stica. El mismo se ejecutar√≠a antes de jugar las partidas para evolucionar una poblaci√≥n de vectores de pesos. La funci√≥n de fitness de cada vector de pesos ser√≠a el puntaje promedio obtenido por el agente de Tetris que lo utiliza y esto nos deber√≠a permitir encontrar un conjunto de pesos que maximice el desempe√±o del agente, superando los l√≠mites que ya tenemos y logrando resultados superiores a los puntos actuales del Hill Climbing.
___

## **Bibliograf√≠a y Referencias**

Talbi, E. --G. (2009). Metaheuristics: From design to implementation.
Wiley.

Dellacherie, P. (2003). The (Near) Perfect Tetris Bot.

Russell, S., & Norvig, P. (2010). \_Artificial intelligence: A modern
approach\_ (3rd ed.). Prentice Hall.
